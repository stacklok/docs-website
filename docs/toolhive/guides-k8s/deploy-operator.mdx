---
title: Deploy the operator
description:
  How to deploy the ToolHive operator in a Kubernetes cluster using Helm or
  kubectl
---

## Prerequisites

- A Kubernetes cluster (current and two previous minor versions are supported)
- Permissions to create resources in the cluster
- [`kubectl`](https://kubernetes.io/docs/tasks/tools/) configured to communicate
  with your cluster
- [Helm](https://helm.sh/docs/intro/install/) (v3.10 minimum, v3.14+
  recommended)

## Install the CRDs

![Latest CRD Helm chart release](https://img.shields.io/github/v/release/stacklok/toolhive?filter=toolhive-operator-crds-*&style=for-the-badge&logo=helm&label=Latest%20CRD%20chart&color=b2e4bc)

The ToolHive operator requires Custom Resource Definitions (CRDs) to manage
MCPServer resources. The CRDs define the structure and behavior of MCPServers in
your cluster.

Choose an installation method based on your needs:

- **Helm** (recommended): Provides customization options and manages the full
  lifecycle of the operator. CRDs are installed and upgraded automatically as
  part of the Helm chart.
- **kubectl**: Uses static manifests for a simple installation. Useful for
  environments where Helm isn't available or for GitOps workflows.

<Tabs groupId="method" queryString="method">
<TabItem value="helm" label="Helm" default>

```bash
helm upgrade --install toolhive-operator-crds oci://ghcr.io/stacklok/toolhive/toolhive-operator-crds
```

This command installs the latest version of the ToolHive operator CRDs Helm
chart. To install a specific version, append `--version <VERSION>` to the
command, for example:

```bash
helm upgrade --install toolhive-operator-crds oci://ghcr.io/stacklok/toolhive/toolhive-operator-crds --version 0.0.73
```

#### CRD configuration options

The Helm chart provides fine-grained control over which CRDs are installed. By
default, all CRDs are installed. You can selectively enable or disable CRD
groups using these values:

| Value                     | Description                                           | Default |
| ------------------------- | ----------------------------------------------------- | ------- |
| `crds.install.server`     | Install server CRDs (MCPServer, MCPRemoteProxy, etc.) | `true`  |
| `crds.install.registry`   | Install registry CRDs (MCPRegistry)                   | `true`  |
| `crds.install.virtualMcp` | Install vMCP CRDs (VirtualMCPServer, etc.)            | `true`  |
| `crds.keep`               | Preserve CRDs when uninstalling the chart             | `true`  |

For example, to install only server-related CRDs without vMCP support:

```bash
helm upgrade --install toolhive-operator-crds oci://ghcr.io/stacklok/toolhive/toolhive-operator-crds \
  --set crds.install.virtualMcp=false
```

:::note

The `crds.keep` option adds the `helm.sh/resource-policy: keep` annotation to
CRDs, which prevents Helm from deleting them during `helm uninstall`. This
protects your custom resources from accidental deletion. If you want to remove
CRDs during uninstall, set `crds.keep=false`.

:::

</TabItem>
<TabItem value="kubectl" label="kubectl">

To install the CRDs using `kubectl`, run the following, ensuring you only apply
the CRDs you need for the features you plan to use:

```bash
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_mcpexternalauthconfigs.yaml
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_mcptoolconfigs.yaml
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_mcpremoteproxies.yaml
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_mcpservers.yaml
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_mcpgroups.yaml
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_mcpregistries.yaml
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_virtualmcpcompositetooldefinitions.yaml
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_virtualmcpservers.yaml
```

Replace `0.0.73` in the commands above with your target CRD version.

</TabItem>
</Tabs>

## Install the operator

![Latest Operator Helm chart release](https://img.shields.io/github/v/release/stacklok/toolhive?filter=toolhive-operator-0*&style=for-the-badge&logo=helm&label=Latest%20Operator%20chart&color=b2e4bc)

To install the ToolHive operator using default settings, run the following
command:

```bash
helm upgrade --install toolhive-operator oci://ghcr.io/stacklok/toolhive/toolhive-operator -n toolhive-system --create-namespace
```

This command installs the latest version of the ToolHive operator CRDs Helm
chart. To install a specific version, append `--version <VERSION>` to the
command, for example:

```bash
helm upgrade --install toolhive-operator oci://ghcr.io/stacklok/toolhive/toolhive-operator -n toolhive-system --create-namespace --version 0.5.6
```

Verify the installation:

```bash
kubectl get pods -n toolhive-system
```

After about 30 seconds, you should see the `toolhive-operator` pod running.

Check the logs of the operator pod:

```bash
kubectl logs -f -n toolhive-system <TOOLHIVE_OPERATOR_POD_NAME>
```

This shows you the logs of the operator pod, which can help you debug any
issues. For comprehensive logging and audit capabilities, see the
[Logging infrastructure](./logging.mdx) guide.

## Customize the operator

You can customize the operator installation by providing a `values.yaml` file
with your configuration settings. For example, to change the number of replicas
and set a specific ToolHive version, create a `values.yaml` file:

```yaml title="values.yaml"
operator:
  replicaCount: 2
  toolhiveRunnerImage: ghcr.io/stacklok/toolhive:v0.2.17 # or `latest`
```

Install the operator with your custom values:

```bash {3}
helm upgrade --install toolhive-operator oci://ghcr.io/stacklok/toolhive/toolhive-operator\
  -n toolhive-system --create-namespace\
  -f values.yaml
```

To see all available configuration options, run:

```bash
helm show values oci://ghcr.io/stacklok/toolhive/toolhive-operator
```

## Operator deployment modes

The ToolHive operator supports two distinct deployment modes to accommodate
different security requirements and organizational structures.

### Cluster mode (default)

Cluster mode provides the operator with cluster-wide access to manage MCPServer
resources in any namespace. This is the default mode and is suitable for
platform teams managing MCPServers across the entire cluster.

**Characteristics:**

- Full cluster-wide access to manage MCPServers in any namespace
- Uses `ClusterRole` and `ClusterRoleBinding` for broad permissions
- Simplest configuration and management
- Best for single-tenant clusters or trusted environments

To explicitly configure cluster mode, include the following property in your
Helm `values.yaml` file:

```yaml title="values.yaml"
operator:
  rbac:
    scope: 'cluster'
```

Reference the `values.yaml` file when you install the operator using Helm:

```bash {3}
helm upgrade --install toolhive-operator oci://ghcr.io/stacklok/toolhive/toolhive-operator \
  -n toolhive-system --create-namespace
  -f values.yaml
```

This is the default configuration used in the standard installation commands.

### Namespace mode

Namespace mode restricts the operator's access to only specified namespaces.
This mode is perfect for multi-tenant environments and organizations following
the principle of least privilege.

**Characteristics:**

- Restricted access to only specified namespaces
- Uses `ClusterRole` with namespace-specific `RoleBindings` for precise access
  control
- Enhanced security through reduced blast radius
- Ideal for multi-tenant environments and compliance requirements

To configure namespace mode, include the following in your Helm `values.yaml`:

```yaml title="values.yaml"
operator:
  rbac:
    scope: 'namespace'
    allowedNamespaces:
      - 'team-frontend'
      - 'team-backend'
      - 'staging'
      - 'production'
```

This example lets the operator manage MCPServer resources in the four namespaces
listed in the `allowedNamespaces` property. Adjust the list to match your
environment.

Reference the `values.yaml` file when you install the operator using Helm:

```bash {3}
helm upgrade --install toolhive-operator oci://ghcr.io/stacklok/toolhive/toolhive-operator \
  -n toolhive-system --create-namespace
  -f values.yaml
```

Verify the RoleBindings are created:

```bash
kubectl get rolebinding --all-namespaces | grep toolhive
```

You should see RoleBindings in the specified namespaces, granting the operator
access to manage MCPServers. Example output:

```text
NAMESPACE        NAME                                           ROLE
team-frontend    toolhive-operator-manager-rolebinding          ClusterRole/toolhive-operator-manager-role
team-backend     toolhive-operator-manager-rolebinding          ClusterRole/toolhive-operator-manager-role
staging          toolhive-operator-manager-rolebinding          ClusterRole/toolhive-operator-manager-role
production       toolhive-operator-manager-rolebinding          ClusterRole/toolhive-operator-manager-role
toolhive-system  toolhive-operator-leader-election-rolebinding  Role/toolhive-operator-leader-election-role
```

### Migrate between modes

You can switch between cluster mode and namespace mode by updating the
`values.yaml` file and reapplying the Helm chart as shown above. Migration in
both directions is supported.

## Check operator status

To verify the operator is working correctly:

```bash
# Verify CRDs are installed
kubectl get crd | grep toolhive

# Check operator deployment status
kubectl get deployment -n toolhive-system toolhive-operator

# Check operator service account and RBAC
kubectl get serviceaccount -n toolhive-system
kubectl get clusterrole | grep toolhive
kubectl get clusterrolebinding | grep toolhive

# Check operator pod status
kubectl get pods -n toolhive-system
# Check operator pod logs
kubectl logs -n toolhive-system <TOOLHIVE_OPERATOR_POD_NAME>
```

## Upgrade the operator

To upgrade the ToolHive operator to a new version, you need to upgrade both the
CRDs and the operator installation.

### Upgrade the CRDs

Choose an upgrade method based on your needs:

- **Helm** (recommended): Provides customization options and manages the full
  lifecycle of the operator. CRDs are installed and upgraded automatically as
  part of the Helm chart.
- **kubectl**: Uses static manifests for a simple installation. Useful for
  environments where Helm isn't available or for GitOps workflows.

<Tabs groupId="method" queryString="method">
<TabItem value="helm" label="Helm" default>

![Latest CRD Helm chart release](https://img.shields.io/github/v/release/stacklok/toolhive?filter=toolhive-operator-crds-*&style=for-the-badge&logo=helm&label=Latest%20CRD%20chart&color=b2e4bc)

To upgrade the ToolHive operator to a new version, upgrade the CRDs first by
upgrading with the desired CRDs chart:

```bash
helm upgrade -i toolhive-operator-crds oci://ghcr.io/stacklok/toolhive/toolhive-operator-crds --version 0.0.73
```

</TabItem>
<TabItem value="kubectl" label="kubectl">

To upgrade the CRDs using `kubectl`, run the following, ensuring you only apply
the CRDs you need for the features you want:

```bash
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_mcpexternalauthconfigs.yaml
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_mcptoolconfigs.yaml
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_mcpremoteproxies.yaml
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_mcpservers.yaml
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_mcpgroups.yaml
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_mcpregistries.yaml
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_virtualmcpcompositetooldefinitions.yaml
kubectl apply -f https://raw.githubusercontent.com/stacklok/toolhive/refs/tags/toolhive-operator-crds-0.0.73/deploy/charts/operator-crds/crds/toolhive.stacklok.dev_virtualmcpservers.yaml
```

</TabItem>
</Tabs>

Replace `0.0.73` in the commands above with your target CRD version.

### Upgrade the operator Helm release

Then, upgrade the operator installation using Helm.

![Latest Operator Helm chart release](https://img.shields.io/github/v/release/stacklok/toolhive?filter=toolhive-operator-0*&style=for-the-badge&logo=helm&label=Latest%20Operator%20chart&color=b2e4bc)

```bash
helm upgrade -i toolhive-operator oci://ghcr.io/stacklok/toolhive/toolhive-operator -n toolhive-system --reuse-values
```

This upgrades the operator to the latest version available in the OCI registry.
To upgrade to a specific version, add the `--version` flag:

```bash
helm upgrade -i toolhive-operator oci://ghcr.io/stacklok/toolhive/toolhive-operator -n toolhive-system --reuse-values --version 0.5.6
```

If you have a custom `values.yaml` file, include it with the `-f` flag:

```bash
helm upgrade -i toolhive-operator oci://ghcr.io/stacklok/toolhive/toolhive-operator -n toolhive-system --reuse-values -f values.yaml
```

## Uninstall the operator

To uninstall the operator and CRDs:

First, uninstall the operator:

```bash
helm uninstall toolhive-operator -n toolhive-system
```

Then, if you want to completely remove ToolHive including all CRDs and related
resources, delete the CRDs.

:::warning

This will delete all MCPServer and related resources in your cluster!

:::

<Tabs groupId="method" queryString="method">
<TabItem value="helm" label="Helm" default>

```bash
helm uninstall toolhive-operator-crds
```

:::note

If you installed the CRDs with Helm and have `crds.keep` still set to `true`,
first upgrade the chart with `--set crds.keep=false` so that when you uninstall
the CRDs chart, it completely removes all CRDs too:

```bash
helm upgrade toolhive-operator-crds oci://ghcr.io/stacklok/toolhive/toolhive-operator-crds --set crds.keep=false
```

:::

</TabItem>
<TabItem value="kubectl" label="kubectl">

To remove the CRDs using `kubectl`, run the following:

```bash
kubectl delete crd mcpexternalauthconfigs.toolhive.stacklok.dev
kubectl delete crd mcptoolconfigs.toolhive.stacklok.dev
kubectl delete crd mcpremoteproxies.toolhive.stacklok.dev
kubectl delete crd mcpservers.toolhive.stacklok.dev
kubectl delete crd mcpgroups.toolhive.stacklok.dev
kubectl delete crd mcpregistries.toolhive.stacklok.dev
kubectl delete crd virtualmcpcompositetooldefinitions.toolhive.stacklok.dev
kubectl delete crd virtualmcpservers.toolhive.stacklok.dev
```

</TabItem>
</Tabs>

If you created the `toolhive-system` namespace with Helm's `--create-namespace`
flag, delete it manually:

```bash
kubectl delete namespace toolhive-system
```

## Next steps

See [Run MCP servers in Kubernetes](./run-mcp-k8s.mdx) to learn how to create
and manage MCP servers using the ToolHive operator in your Kubernetes cluster.
The operator supports deploying MCPServer resources based on the deployment mode
configured during installation.

## Related information

- [Kubernetes introduction](./intro.mdx) - Overview of ToolHive's Kubernetes
  integration
- [ToolHive operator tutorial](../tutorials/quickstart-k8s.mdx) - Step-by-step
  tutorial for getting started using a local kind cluster

## Troubleshooting

<details>
<summary>Authentication error with ghcr.io</summary>

If you encounter an authentication error when pulling the Helm chart, it might
indicate a problem with your access to the GitHub Container Registry
(`ghcr.io`).

ToolHive's charts and images are public, but if you've previously logged into
`ghcr.io` using a personal access token, you might need to re-authenticate if
your token has expired or been revoked.

See the GitHub documentation to
[re-authenticate to the registry](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry#authenticating-with-a-personal-access-token-classic).

</details>

<details>
<summary>Operator pod fails to start</summary>

If the operator pod is not starting or is in a `CrashLoopBackOff` state, check
the pod logs for error messages:

```bash
kubectl get pods -n toolhive-system
# Note the name of the toolhive-operator pod

kubectl describe pod -n toolhive-system <TOOLHIVE_OPERATOR_POD_NAME>
kubectl logs -n toolhive-system <TOOLHIVE_OPERATOR_POD_NAME>
```

Common causes include:

- **Missing CRDs**: Ensure the CRDs were installed successfully before
  installing the operator. The operator requires the CRDs to function properly.
- **Configuration errors**: Check your `values.yaml` file for any
  misconfigurations
- **Insufficient permissions**: Ensure your cluster has the necessary RBAC
  permissions for the operator to function
- **Resource constraints**: Check if the cluster has sufficient CPU and memory
  resources available
- **Image pull issues**: Verify that the cluster can pull images from `ghcr.io`

</details>

<details>
<summary>CRDs installation fails</summary>

If the CRDs installation fails, you might see errors about existing resources or
permission issues:

```bash
# Check if CRDs already exist
kubectl get crd | grep toolhive

# Remove existing CRDs if needed (this will delete all related resources)
kubectl delete crd <CRD_NAME>
```

To reinstall the CRDs:

```bash
helm uninstall toolhive-operator-crds
helm upgrade -i toolhive-operator-crds oci://ghcr.io/stacklok/toolhive/toolhive-operator-crds
```

</details>

<details>
<summary>Namespace creation issues</summary>

If you encounter permission errors when creating the `toolhive-system`
namespace, create it manually first:

```bash
kubectl create namespace toolhive-system
```

Then install the operator without the `--create-namespace` flag:

```bash
helm upgrade -i toolhive-operator oci://ghcr.io/stacklok/toolhive/toolhive-operator -n toolhive-system
```

</details>

<details>
<summary>Helm chart not found</summary>

If Helm cannot find the chart, ensure you're using the correct OCI registry URL
and that your Helm version supports OCI registries (v3.8.0+):

```bash
# Check Helm version
helm version

# Try pulling the chart explicitly
helm pull oci://ghcr.io/stacklok/toolhive/toolhive-operator
```

</details>

<details>
<summary>Network connectivity issues</summary>

If you're experiencing network timeouts or connection issues:

- Verify your cluster has internet access to reach `ghcr.io`
- Check if your organization uses a proxy or firewall that might block access
- Consider using a private registry mirror if direct access is restricted

</details>
